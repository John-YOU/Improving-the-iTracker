{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import caffe\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import cv2\n",
    "from sklearn import *\n",
    "from numpy import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/youhan/Documents/face-landmark-localization-master/')\n",
    "import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe_root='/Users/youhan/Documents/17-18/fyp/caffe-master/'\n",
    "sys.path.insert(0, caffe_root + 'python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CaffeNet found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.path.isfile(caffe_root + 'models/gazecapture/snapshots/itracker25x_iter_92000.caffemodel'):\n",
    "    print 'CaffeNet found.'\n",
    "else:\n",
    "    print 'Downloading pre-trained CaffeNet model...'\n",
    "    #!../scripts/download_model_binary.py ../models/bvlc_reference_caffenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "model_def = caffe_root + 'models/gazecapture/itracker_deploy.prototxt'\n",
    "model_weights = caffe_root + 'models/gazecapture/snapshots/itracker_iter_92000.caffemodel'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "            model_weights,  # contains the trained weights\n",
    "            caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-subtracted values: [('R', 97.515486925080126), ('G', 105.81451976649006), ('B', 141.64970855947053)]\n",
      "mean-subtracted values: [('R', 93.259237833473136), ('G', 102.0830842169876), ('B', 135.04557388640788)]\n",
      "mean-subtracted values: [('R', 100.96920115044531), ('G', 112.32869105208285), ('B', 148.36621669953573)]\n"
     ]
    }
   ],
   "source": [
    "# load the mean ImageNet image (as distributed with Caffe) for subtraction\n",
    "mleft = np.load(caffe_root + 'models/gazecapture/mean_images/left.npy')\n",
    "mleft = mleft.mean(1).mean(1)  # average over pixels to obtain the mean (RGB) pixel values\n",
    "print 'mean-subtracted values:', zip('RGB', mleft)\n",
    "\n",
    "mright = np.load(caffe_root + 'models/gazecapture/mean_images/right.npy')\n",
    "mright = mright.mean(1).mean(1)  # average over pixels to obtain the mean (RGB) pixel values\n",
    "print 'mean-subtracted values:', zip('RGB', mright)\n",
    "\n",
    "mface = np.load(caffe_root + 'models/gazecapture/mean_images/face.npy')\n",
    "mface = mface.mean(1).mean(1)  # average over pixels to obtain the mean (RGB) pixel values\n",
    "print 'mean-subtracted values:', zip('RGB', mface)\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformerl = caffe.io.Transformer({'image_left': net.blobs['image_left'].data.shape})\n",
    "transformer2 = caffe.io.Transformer({'image_right': net.blobs['image_right'].data.shape})\n",
    "transformer3 = caffe.io.Transformer({'image_face': net.blobs['image_face'].data.shape})\n",
    "transformer4= caffe.io.Transformer({'facegrid': net.blobs['facegrid'].data.shape})\n",
    "\n",
    "transformerl.set_transpose('image_left', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer2.set_transpose('image_right', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer3.set_transpose('image_face', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer4.set_transpose('facegrid', (2,0,1))\n",
    "\n",
    "transformerl.set_mean('image_left', mleft)            # subtract the dataset-mean value in each channel\n",
    "transformer2.set_mean('image_right', mright)            # subtract the dataset-mean value in each channel\n",
    "transformer3.set_mean('image_face', mface)            # subtract the dataset-mean value in each channel\n",
    "\n",
    "transformerl.set_raw_scale('image_left', 255)\n",
    "transformer2.set_raw_scale('image_right', 255) \n",
    "transformer3.set_raw_scale('image_face', 255) \n",
    "#transformer4.set_raw_scale('facegrid', 255) \n",
    "\n",
    "# rescale from [0, 1] to [0, 255]\n",
    "transformerl.set_channel_swap('image_left', (2,1,0))\n",
    "transformer2.set_channel_swap('image_right', (2,1,0)) \n",
    "transformer3.set_channel_swap('image_face', (2,1,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paths=[]\\npaths[:]=['/Users/youhan/Documents/GitHub/GazeCapture-master/data/00006/frames/0000'+str(i)+'.jpg' for i in range(0,10)]\\npfile='paths.txt'\\npath_file=open(pfile,'w')\\nfor i in paths:\\n    path_file.write(i+'\\n')\\npath_file.close()\\ntest.predictImage(pfile) \""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''paths=[]\n",
    "paths[:]=['/Users/youhan/Documents/GitHub/GazeCapture-master/data/00006/frames/0000'+str(i)+'.jpg' for i in range(0,10)]\n",
    "pfile='paths.txt'\n",
    "path_file=open(pfile,'w')\n",
    "for i in paths:\n",
    "    path_file.write(i+'\\n')\n",
    "path_file.close()\n",
    "test.predictImage(pfile) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processBatch(imgsl,imgsr,imgsf,grids,net):\n",
    "    imgs_l=[];imgs_r=[];imgs_f=[];imgs_g=[]\n",
    "    for i in range(len(imgsl)):\n",
    "        net.blobs['image_left'].data[...][i] = transformerl.preprocess('image_left',imgsl[i])\n",
    "\n",
    "        net.blobs['image_right'].data[...][i] = transformer2.preprocess('image_right',imgsr[i])\n",
    "\n",
    "        net.blobs['image_face'].data[...][i] = transformer3.preprocess('image_face',imgsf[i])\n",
    "    \n",
    "        net.blobs['facegrid'].data[...] = transformer4.preprocess('facegrid',grids[i])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='deng/test'\n",
    "path='/Users/youhan/Documents/FYP/mapping_data/'+name+'/'\n",
    "flist=glob.glob(path+\"/raw/*\")\n",
    "n=len(flist)\n",
    "imleft=[]\n",
    "imright=[]\n",
    "imface=[]\n",
    "masks=[]\n",
    "with open('/Users/youhan/Documents/FYP/work/points'+str(n)) as f:\n",
    "    lines = f.read().splitlines()\n",
    "g_truth=[]\n",
    "for i in lines:\n",
    "    g_truth.append((int(i.split(\" \")[1]),int(i.split(\" \")[2])))\n",
    "\n",
    "\n",
    "net.blobs['image_left'].reshape(n,        # batch size\n",
    "                      3,         # 3-channel (RGB) images\n",
    "                      224, 224)  # image size is 227x227\n",
    "net.blobs['image_right'].reshape(n,        # batch size\n",
    "                          3,         # 3-channel (RGB) images\n",
    "                          224, 224)  # image size is 227x227\n",
    "net.blobs['image_face'].reshape(n,        # batch size\n",
    "                          3,         # 3-channel (RGB) images\n",
    "                          224, 224)  # image size is 227x227\n",
    "net.blobs['facegrid'].reshape(n,\n",
    "                              625\n",
    "                              ,1,1)\n",
    "\n",
    "\n",
    "for i in range(0,n):\n",
    "    imleft.append(caffe.io.load_image('/Users/youhan/Documents/FYP/mapping_data/'+name+'/eyeLeft/f'+str(i)+'eye2.jpg'))\n",
    "    #print net.blobs['image_left'].data[0][0][0][0:3]\n",
    "\n",
    "    imright.append(caffe.io.load_image('/Users/youhan/Documents/FYP/mapping_data/'+name+'/eyeRight/f'+str(i)+'eye1.jpg'))\n",
    "\n",
    "    imface.append(caffe.io.load_image('/Users/youhan/Documents/FYP/mapping_data/'+name+'/face/face'+str(i)+'.jpg'))\n",
    "\n",
    "    with open('/Users/youhan/Documents/FYP/mapping_data/'+name+'/grid/face_grid'+str(i), 'r') as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "        mask=data.split()\n",
    "        #mask=[[mask]]\n",
    "        mask=zip(zip(mask))\n",
    "        masks.append(np.array(mask))\n",
    "\n",
    "net=processBatch(imleft,imright,imface,masks,net)\n",
    "data=net.forward()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x        y          real_x       real_y\n",
      "1   -3.918   -1.622     -708         -12  \n",
      "2   -0.051   -1.418     0            -12  \n",
      "3   4.4938   -0.183     708          -12  \n",
      "4   -4.725   -3.120     -708         -450 \n",
      "5   0.0829   -3.424     0            -450 \n",
      "6   4.4238   -2.285     708          -450 \n",
      "7   -4.629   -5.199     -708         -888 \n",
      "8   0.0444   -5.366     0            -888 \n",
      "9   4.2210   -5.718     708          -888 \n",
      "10  -2.379   -2.284     -360         -225 \n",
      "11  1.3017   -2.618     360          -225 \n",
      "12  -2.372   -4.370     -360         -675 \n",
      "13  1.5188   -4.326     360          -675 \n",
      "14  -2.213   -1.245     -360         -12  \n",
      "15  1.6517   -0.793     360          -12  \n",
      "16  -2.835   -2.959     -360         -450 \n",
      "17  1.6449   -3.084     360          -450 \n",
      "18  -1.908   -5.694     -360         -888 \n",
      "19  1.6104   -5.237     360          -888 \n",
      "20  -5.017   -2.613     -708         -225 \n",
      "21  -0.303   -2.049     0            -225 \n",
      "22  4.1095   -1.009     708          -225 \n",
      "23  -4.127   -4.042     -708         -675 \n",
      "24  0.0627   -4.583     0            -675 \n",
      "25  4.0313   -4.218     708          -675 \n",
      "26  -5.421   -1.515     -708         -12  \n",
      "27  -0.074   -0.804     0            -12  \n",
      "28  4.5503   -0.153     708          -12  \n",
      "29  -4.650   -3.009     -708         -450 \n",
      "30  -0.195   -3.370     0            -450 \n",
      "31  4.1172   -2.001     708          -450 \n",
      "32  -4.651   -5.031     -708         -888 \n",
      "33  0.0855   -5.797     0            -888 \n",
      "34  4.2579   -4.816     708          -888 \n"
     ]
    }
   ],
   "source": [
    "print \"    x        y          real_x       real_y\" # relative to the camera\n",
    "to_file=[]\n",
    "for i in range(0,n):\n",
    "    #sys.stdout.write(\"{:<3}{:<6}{:<15}{:<7}{:<7}\\n\".format(i+1, data['fc3'][i][0],data['fc3'][i][1], g_truth[i][0], g_truth[i][1]))\n",
    "    line= \"%-2d  %.6s   %.6s     %-4s         %-4s \" %(i+1, str(data['fc3'][i][0]), \\\n",
    "                                                       str(data['fc3'][i][1]), g_truth[i][0], g_truth[i][1])\n",
    "    print line\n",
    "    to_file.append(line)\n",
    "\n",
    "f = open(path+name+\"_reference_table.txt\", 'w')\n",
    "[f.write(i+\"\\n\") for i in to_file]  # python will convert \\n to os.linesep\n",
    "f.close()                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  [-389.91644287 -256.75878906] (-360, -225) (-29.91644287109375, -31.7587890625) 43.6304278775\n",
      "2:  [ 205.72340393 -364.95159912] (360, -225) (-154.27659606933594, -139.95159912109375) 208.29718719\n",
      "3:  [-369.60858154 -653.76544189] (-360, -675) (-9.60858154296875, 21.23455810546875) 23.3073228236\n",
      "4:  [ 256.34609985 -692.50695801] (360, -675) (-103.65390014648438, -17.5069580078125) 105.121951058\n",
      "5:  [-372.7467041   -61.11090088] (-360, -12) (-12.7467041015625, -49.11090087890625) 50.7381419702\n",
      "6:  [ 245.29606628  -21.8273468 ] (360, -12) (-114.70393371582031, -9.8273468017578125) 115.124146707\n",
      "7:  [-457.03469849 -379.66870117] (-360, -450) (-97.034698486328125, 70.331298828125) 119.842497909\n",
      "8:  [ 265.23498535 -457.68725586] (360, -450) (-94.7650146484375, -7.687255859375) 95.0762951738\n",
      "9:  [-282.75439453 -911.34387207] (-360, -888) (77.24560546875, -23.3438720703125) 80.6958482666\n",
      "10:  [ 279.44668579 -867.02459717] (360, -888) (-80.553314208984375, 20.97540283203125) 83.2394374922\n",
      "11:  [-811.43310547 -287.54620361] (-708, -225) (-103.43310546875, -62.54620361328125) 120.873631919\n",
      "12:  [ -57.8611412  -237.20513916] (0, -225) (-57.861141204833984, -12.20513916015625) 59.1343984788\n",
      "13:  [ 642.91052246  -92.75935364] (708, -225) (-65.0894775390625, 132.24064636230469) 147.391413036\n",
      "14:  [-655.0612793 -570.0925293] (-708, -675) (52.938720703125, 104.907470703125) 117.50781063\n",
      "15:  [  24.32724571 -723.88208008] (0, -675) (24.327245712280273, -48.882080078125) 54.601031462\n",
      "16:  [ 659.77392578 -702.41729736] (708, -675) (-48.22607421875, -27.41729736328125) 55.4748810657\n",
      "17:  [-886.55633545  -73.72331238] (-708, -12) (-178.55633544921875, -61.723312377929688) 188.923614776\n",
      "18:  [-32.39260864  -3.11291504] (0, -12) (-32.392608642578125, 8.8870849609375) 33.5896021675\n",
      "19:  [ 706.00469971   64.84388733] (708, -12) (-1.99530029296875, 76.843887329101562) 76.8697875833\n",
      "20:  [-748.84356689 -367.22900391] (-708, -450) (-40.84356689453125, 82.77099609375) 92.2997007093\n",
      "21:  [ -28.33550453 -489.93164062] (0, -450) (-28.335504531860352, -39.931640625) 48.9636267047\n",
      "22:  [ 653.24725342 -281.55114746] (708, -450) (-54.75274658203125, 168.4488525390625) 177.123909115\n",
      "23:  [-730.3258667  -752.06066895] (-708, -888) (-22.32586669921875, 135.9393310546875) 137.760466214\n",
      "24:  [  39.1403656  -955.06005859] (0, -888) (39.140365600585938, -67.06005859375) 77.6467621858\n",
      "25:  [ 701.74621582 -818.88275146] (708, -888) (-6.2537841796875, 69.11724853515625) 69.3995955438\n",
      "mean error 95.3053395223\n"
     ]
    }
   ],
   "source": [
    "m=9 #number of calibration points\n",
    "trainX=[data['fc3'][i] for i in range(0,m)]\n",
    "testX=[data['fc3'][i] for i in range(m,n)]\n",
    "trainY=[g_truth[i] for i in range(0,m)]\n",
    "testY=[g_truth[i] for i in range(m,n)]\n",
    "\n",
    "paramgrid={'C':logspace(-4,4,20)}\n",
    "\n",
    "logreg = linear_model.LinearRegression()#6, 0.8145\n",
    "logreg.fit(trainX, trainY)\n",
    "predictY=logreg.predict(testX)\n",
    "\n",
    "count=0.0\n",
    "for i in range(0,n-m):\n",
    "    tmp=np.linalg.norm((predictY[i][0]-testY[i][0],predictY[i][1]-testY[i][1]))\n",
    "    count+=tmp\n",
    "    print str(i+1)+\": \", predictY[i], testY[i], (predictY[i][0]-testY[i][0],predictY[i][1]-testY[i][1]), tmp\n",
    "print \"mean error\", count/(n-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
